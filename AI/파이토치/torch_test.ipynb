{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPMlcLaKTVoKF82IHiAfkQg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssosoo/2024_DS60/blob/main/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98/torch_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "gSAnvZkhnMv_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjPBGluPnF-f",
        "outputId": "21a1cc75-d2fc-4232-9d90-92ca32b5370d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5537, 0.8445]])\n",
            "torch.Size([1, 2])\n",
            "torch.float32\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# 텐서 속성\n",
        "tensor = torch.rand(1, 2)\n",
        "print(tensor)\n",
        "print(tensor.shape) #차원 정보\n",
        "print(tensor.dtype) #자료형\n",
        "print(tensor.device)#GPU 가속 여부"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 차원 변환\n",
        "tensor = tensor.reshape(2, 1) #전치\n",
        "print(tensor)\n",
        "print(tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SovzH68FnpGI",
        "outputId": "f2a74c85-a688-4bc7-cd79-673724e025e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5537],\n",
            "        [0.8445]])\n",
            "torch.Size([2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 자료형 설정\n",
        "tensor = torch.rand((3,3), dtype=torch.float) #float는 64비트\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBicpcswpzKo",
        "outputId": "cc82857e-d93d-44b8-f266-3f1064dca9da"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2326, 0.6192, 0.1636],\n",
            "        [0.0038, 0.9567, 0.3678],\n",
            "        [0.4729, 0.7583, 0.6396]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 장치 설정\n",
        "# CPU로 설정될 경우 연산에 소요시간이 증가된다.\n",
        "# M1맥은 CUDA x, mps를 사용한다.\n",
        "\n",
        "\n",
        "# GPU(MPS) 지원 여부 확인\n",
        "# device = \"mps\" if torch.backends.mps.is_available() and torch.backends.mps.is_built() else \"cpu\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Tensor 생성\n",
        "cpu = torch.FloatTensor([1, 2, 3])  # CPU Tensor\n",
        "gpu = torch.tensor([1, 2, 3], device=device)  # MPS(GPU) Tensor\n",
        "tensor = torch.rand((1, 1), device=device)\n",
        "\n",
        "print(device)\n",
        "print(cpu)\n",
        "print(gpu)\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poSvlN-XqCgZ",
        "outputId": "de51af97-2551-4bfc-93ab-0e870f63f98e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "tensor([1., 2., 3.])\n",
            "tensor([1, 2, 3], device='cuda:0')\n",
            "tensor([[0.8187]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 장치 변환\n",
        "cpu = torch.FloatTensor([1, 2, 3])\n",
        "gpu = cpu.cuda()\n",
        "gpu2cpu = gpu.cpu()\n",
        "cpu2gpu = cpu.to(\"cuda\")\n",
        "print(cpu)\n",
        "print(gpu)\n",
        "print(gpu2cpu)\n",
        "print(cpu2gpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VFBsmI9rURT",
        "outputId": "04a39fe9-6547-48b5-94cb-72d136121cdd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.])\n",
            "tensor([1., 2., 3.], device='cuda:0')\n",
            "tensor([1., 2., 3.])\n",
            "tensor([1., 2., 3.], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU 호출 방식\n",
        "\n",
        "1. device: gpu가 없을 경우 자동으로 cpu 호출\n",
        "2. .cuda(): gpu가 없을 경우 ERROR"
      ],
      "metadata": {
        "id": "Ro22ugNT8oGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy 배열의 텐서 변환\n",
        "import numpy as np\n",
        "ndarray = np.array([1,2,3], dtype=np.uint8)\n",
        "torch.tensor(ndarray)\n",
        "torch.Tensor(ndarray)\n",
        "torch.from_numpy(ndarray)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqoHCqdE7LtE",
        "outputId": "ccae1c9b-43f5-429a-e792-c6779bce9de9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서의 numpy 변환\n",
        "tensor = torch.cuda.FloatTensor([1,2,3])\n",
        "ndarray = tensor.detach().cpu().numpy()\n",
        "ndarray\n",
        "type(ndarray)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM9-H9iM-Dvm",
        "outputId": "ae0538dc-284e-44a6-9c35-d6300ac8fcf9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-c3de2d5b10a8>:2: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  tensor = torch.cuda.FloatTensor([1,2,3])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}